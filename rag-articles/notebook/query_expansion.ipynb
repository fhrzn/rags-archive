{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query Expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '2', '3']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_core.documents import Document\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "import os\n",
    "\n",
    "oai = OpenAIEmbeddings(api_key=os.getenv(\"OPENAI_API_KEY\"), model=\"text-embedding-3-small\")\n",
    "\n",
    "docs = [\n",
    "    Document(id=1, page_content=\"Employees have 20 leaves per year.\"),\n",
    "    Document(id=2, page_content=\"Apply for leave in the HR portal.\"),\n",
    "    Document(id=3, page_content=\"Remote work policies are in the handbook.\"),\n",
    "]\n",
    "\n",
    "vectorstore = InMemoryVectorStore(oai)\n",
    "await vectorstore.aadd_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "SIMILARITY_THRESHOLD = 0.5\n",
    "\n",
    "@tool\n",
    "async def retrieve(contextual_query: str):\n",
    "    '''Retrieve relevant document for given query'''\n",
    "\n",
    "    docs = [doc.page_content for doc, sim in \n",
    "            vectorstore.similarity_search_with_score(contextual_query) \n",
    "            if sim >= SIMILARITY_THRESHOLD]\n",
    "    \n",
    "    return \"\\n\".join(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import HumanMessage, ToolMessage, AIMessage, SystemMessage\n",
    "\n",
    "TOOLS = {\"retrieve\": retrieve}\n",
    "\n",
    "system_prompt = '''You are a helpful internal HR assistant.\n",
    "You are given a tool called `retrieve` to search for relevant documents based on a given query.\n",
    "When invoking the tool, always enrich the query with the context based on chat history.'''\n",
    "\n",
    "history = [\n",
    "    SystemMessage(system_prompt),\n",
    "    HumanMessage(\"How many leaves do I get?\"),\n",
    "    AIMessage(\"\", tool_calls=[{\"id\": \"1\", \"name\": \"retrieve\", \"args\": {\"contextual_query\": \"employee leave entitlements and policies\"}}]),\n",
    "    ToolMessage(\"Employees have 20 leaves per year.\", tool_call_id=\"1\"),\n",
    "    AIMessage(\"You have 20 days annuallly.\"),\n",
    "    (\"human\", \"{query}\")\n",
    "]\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(history)\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.5).bind_tools([retrieve])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm\n",
    "res = chain.invoke(input={\"query\": \"and how do I apply?\"})\n",
    "history.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': '',\n",
       " 'additional_kwargs': {'tool_calls': [{'id': 'call_zs7ikbtL9dIKDAmmcgccMO6f',\n",
       "    'function': {'arguments': '{\"contextual_query\":\"how to apply for leave as an employee\"}',\n",
       "     'name': 'retrieve'},\n",
       "    'type': 'function'}],\n",
       "  'refusal': None},\n",
       " 'response_metadata': {'token_usage': {'completion_tokens': 22,\n",
       "   'prompt_tokens': 155,\n",
       "   'total_tokens': 177,\n",
       "   'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "    'audio_tokens': 0,\n",
       "    'reasoning_tokens': 0,\n",
       "    'rejected_prediction_tokens': 0},\n",
       "   'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
       "  'model_name': 'gpt-4o-mini-2024-07-18',\n",
       "  'system_fingerprint': 'fp_34a54ae93c',\n",
       "  'id': 'chatcmpl-BdKvu9ELvfWd6utMM4ERotJmX3JlP',\n",
       "  'service_tier': 'default',\n",
       "  'finish_reason': 'tool_calls',\n",
       "  'logprobs': None},\n",
       " 'type': 'ai',\n",
       " 'name': None,\n",
       " 'id': 'run--4361b2a2-661f-4dc7-93a0-3f8c413eb736-0',\n",
       " 'example': False,\n",
       " 'tool_calls': [{'name': 'retrieve',\n",
       "   'args': {'contextual_query': 'how to apply for leave as an employee'},\n",
       "   'id': 'call_zs7ikbtL9dIKDAmmcgccMO6f',\n",
       "   'type': 'tool_call'}],\n",
       " 'invalid_tool_calls': [],\n",
       " 'usage_metadata': {'input_tokens': 155,\n",
       "  'output_tokens': 22,\n",
       "  'total_tokens': 177,\n",
       "  'input_token_details': {'audio': 0, 'cache_read': 0},\n",
       "  'output_token_details': {'audio': 0, 'reasoning': 0}}}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "while res.tool_calls:\n",
    "    for tcall in res.tool_calls:\n",
    "        msg = await TOOLS[tcall['name'].lower()].ainvoke(tcall)\n",
    "        history.append(msg)\n",
    "    res = chain.invoke(history)\n",
    "    history.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To apply for leave, you can do so through the HR portal. Remember, you have 20 leaves available per year.\n"
     ]
    }
   ],
   "source": [
    "print(res.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
